{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":68699,"databundleVersionId":7659021,"sourceType":"competition"}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>1 |</span></b> <b>INTRODUCTION</b></div>","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#FFCE30'> 1.1 |</span> Objective</b>\n- In this notebook we will perform some simple EDA to check the dataset\n- Thereafter we will use a pipeline to perform the necessary data preprocessing with minimal feature engineering\n- We will then use permutation importance / SHAP Value / and feature importance to select key features to use for the model (we keep up to 15)\n- Send the model through XGboost with Hyperparameter Optimisation and submit the results","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>LOAD DATA</b></div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Set the display options to show all columns without truncation\npd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:06.1206Z","iopub.execute_input":"2024-03-21T09:29:06.120838Z","iopub.status.idle":"2024-03-21T09:29:08.33437Z","shell.execute_reply.started":"2024-03-21T09:29:06.120816Z","shell.execute_reply":"2024-03-21T09:29:08.333359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the data\ntrain = pd.read_csv(\"/kaggle/input/playground-series-s4e3/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/playground-series-s4e3/test.csv\")\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s4e3/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:08.33643Z","iopub.execute_input":"2024-03-21T09:29:08.336924Z","iopub.status.idle":"2024-03-21T09:29:08.590655Z","shell.execute_reply.started":"2024-03-21T09:29:08.336893Z","shell.execute_reply":"2024-03-21T09:29:08.589676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:08.591851Z","iopub.execute_input":"2024-03-21T09:29:08.592213Z","iopub.status.idle":"2024-03-21T09:29:08.638331Z","shell.execute_reply.started":"2024-03-21T09:29:08.592182Z","shell.execute_reply":"2024-03-21T09:29:08.637287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:08.640371Z","iopub.execute_input":"2024-03-21T09:29:08.640672Z","iopub.status.idle":"2024-03-21T09:29:08.668968Z","shell.execute_reply.started":"2024-03-21T09:29:08.640649Z","shell.execute_reply":"2024-03-21T09:29:08.6678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:08.670236Z","iopub.execute_input":"2024-03-21T09:29:08.670647Z","iopub.status.idle":"2024-03-21T09:29:08.692118Z","shell.execute_reply.started":"2024-03-21T09:29:08.670614Z","shell.execute_reply":"2024-03-21T09:29:08.691183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>EDA</b></div>\n- No missing data in both train and test set\n- No catgorical data\n- Last 7 columns of train data are target variable to predict","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#FFCE30'> 3.1 |</span> Train data</b>","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:49:51.014675Z","iopub.execute_input":"2024-03-06T14:49:51.015121Z","iopub.status.idle":"2024-03-06T14:49:51.019975Z","shell.execute_reply.started":"2024-03-06T14:49:51.015087Z","shell.execute_reply":"2024-03-06T14:49:51.018808Z"}}},{"cell_type":"code","source":"train.describe().T.style.background_gradient(cmap='Oranges').format(\"{:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:08.694795Z","iopub.execute_input":"2024-03-21T09:29:08.695777Z","iopub.status.idle":"2024-03-21T09:29:08.967587Z","shell.execute_reply.started":"2024-03-21T09:29:08.695743Z","shell.execute_reply":"2024-03-21T09:29:08.966515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:08.968778Z","iopub.execute_input":"2024-03-21T09:29:08.969227Z","iopub.status.idle":"2024-03-21T09:29:08.991809Z","shell.execute_reply.started":"2024-03-21T09:29:08.969195Z","shell.execute_reply":"2024-03-21T09:29:08.990924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = train.columns\ncols","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:08.993084Z","iopub.execute_input":"2024-03-21T09:29:08.993437Z","iopub.status.idle":"2024-03-21T09:29:09.001913Z","shell.execute_reply.started":"2024-03-21T09:29:08.993411Z","shell.execute_reply":"2024-03-21T09:29:09.00075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum',\n       'Pixels_Areas', 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas']\n\ncolors = ['lightblue', 'orange']  \n\nnum_plots = len(cols)\nnum_cols = 3  \nnum_rows = -(-num_plots // num_cols)  \nfig, axes = plt.subplots(num_rows, num_cols, figsize=(21, 5 * num_rows))  # Adjust the figure size as needed\n\nfor i, feature in enumerate(cols):\n    row = i // num_cols\n    col = i % num_cols\n\n    ax = axes[row, col] if num_rows > 1 else axes[col]\n    \n    sns.histplot(train[feature], kde=True, color=colors[0], label='Train', alpha=0.5, bins=30, ax=ax)\n    sns.histplot(test[feature], kde=True, color=colors[1], label='Test', alpha=0.5, bins=30, ax=ax)\n    \n    ax.set_title(f'Distribution of {feature}')\n    ax.set_xlabel(feature)\n    ax.set_ylabel('Frequency')\n    ax.legend()\n\nif num_plots % num_cols != 0:\n    for j in range(num_plots % num_cols, num_cols):\n        axes[-1, j].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:09.002913Z","iopub.execute_input":"2024-03-21T09:29:09.003285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains',\n       'Dirtiness', 'Bumps', 'Other_Faults']\nplt.figure(figsize=(20,20))\n\nfor i, column in enumerate(target_cols):\n    plt.subplot(9,4, i+1)\n    sns.histplot(data=train, x=column, kde=True, bins=30)\n    plt.title(f'{column} distribution')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.idle":"2024-03-21T09:29:31.62518Z","shell.execute_reply.started":"2024-03-21T09:29:28.129874Z","shell.execute_reply":"2024-03-21T09:29:31.624285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr = train[train.columns].dropna().corr()\nplt.figure(figsize=(30, 20))\n\n# Plot the heatmap\nsns.heatmap(df_corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:31.626315Z","iopub.execute_input":"2024-03-21T09:29:31.626633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#FFCE30'> 3.2 |</span> Test Data</b>","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:50:12.807961Z","iopub.execute_input":"2024-03-06T14:50:12.808415Z","iopub.status.idle":"2024-03-06T14:50:12.813185Z","shell.execute_reply.started":"2024-03-06T14:50:12.808375Z","shell.execute_reply":"2024-03-06T14:50:12.812243Z"}}},{"cell_type":"code","source":"test.describe().T.style.background_gradient(cmap='Oranges').format(\"{:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:34.945967Z","iopub.execute_input":"2024-03-21T09:29:34.946357Z","iopub.status.idle":"2024-03-21T09:29:35.046611Z","shell.execute_reply.started":"2024-03-21T09:29:34.946328Z","shell.execute_reply":"2024-03-21T09:29:35.045689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.047917Z","iopub.execute_input":"2024-03-21T09:29:35.048299Z","iopub.status.idle":"2024-03-21T09:29:35.059153Z","shell.execute_reply.started":"2024-03-21T09:29:35.048264Z","shell.execute_reply":"2024-03-21T09:29:35.058208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>DATA PREPROCESSING</b></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.060396Z","iopub.execute_input":"2024-03-21T09:29:35.060776Z","iopub.status.idle":"2024-03-21T09:29:35.105085Z","shell.execute_reply.started":"2024-03-21T09:29:35.060739Z","shell.execute_reply":"2024-03-21T09:29:35.104392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#FFCE30'> 4.1 |</span> Drop Columns</b>","metadata":{"execution":{"iopub.status.busy":"2024-03-07T00:32:44.770932Z","iopub.status.idle":"2024-03-07T00:32:44.772432Z","shell.execute_reply.started":"2024-03-07T00:32:44.771756Z","shell.execute_reply":"2024-03-07T00:32:44.771888Z"}}},{"cell_type":"code","source":"class DropColumn(BaseEstimator, TransformerMixin):\n    def __init__(self, cols=[]):\n        self.cols = cols\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n\n        return X.drop(self.cols, axis=1)\n\nDropColumn(cols=['id']).fit_transform(train)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.10607Z","iopub.execute_input":"2024-03-21T09:29:35.10649Z","iopub.status.idle":"2024-03-21T09:29:35.142694Z","shell.execute_reply.started":"2024-03-21T09:29:35.10646Z","shell.execute_reply":"2024-03-21T09:29:35.141864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>ASSEMBLING THE PIPELINE</b></div>","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:40:35.578484Z","iopub.execute_input":"2024-03-06T14:40:35.57898Z","iopub.status.idle":"2024-03-06T14:40:35.608496Z","shell.execute_reply.started":"2024-03-06T14:40:35.578925Z","shell.execute_reply":"2024-03-06T14:40:35.607561Z"}}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.pipeline import Pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.143766Z","iopub.execute_input":"2024-03-21T09:29:35.144029Z","iopub.status.idle":"2024-03-21T09:29:35.184934Z","shell.execute_reply.started":"2024-03-21T09:29:35.144008Z","shell.execute_reply":"2024-03-21T09:29:35.184268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"named_preprocessing_pipeline = Pipeline([\n        ('drop', DropColumn(cols=[\n            'id', #id is not a useful feature\n        ]\n                           )\n        ),\n    \n        ('prep', ColumnTransformer(\n            [\n                \n            ],\n            remainder='passthrough').set_output(transform='pandas')\n        ),\n])\n\nnamed_preprocessing_pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.185794Z","iopub.execute_input":"2024-03-21T09:29:35.186037Z","iopub.status.idle":"2024-03-21T09:29:35.199291Z","shell.execute_reply.started":"2024-03-21T09:29:35.186015Z","shell.execute_reply":"2024-03-21T09:29:35.19847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_cols = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.200265Z","iopub.execute_input":"2024-03-21T09:29:35.200524Z","iopub.status.idle":"2024-03-21T09:29:35.206384Z","shell.execute_reply.started":"2024-03-21T09:29:35.200502Z","shell.execute_reply":"2024-03-21T09:29:35.205512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop observations with multiple labels\ntrain = train[train[label_cols].sum(axis=1) <= 1]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.207553Z","iopub.execute_input":"2024-03-21T09:29:35.207868Z","iopub.status.idle":"2024-03-21T09:29:35.222794Z","shell.execute_reply.started":"2024-03-21T09:29:35.207847Z","shell.execute_reply":"2024-03-21T09:29:35.222112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add a label column for the multi-class classification \nsparse_labels = train[label_cols].values.copy()\nsparse_labels = np.concatenate([sparse_labels, 1 - sparse_labels.sum(1)[:, np.newaxis]], axis=1)\ntrain['label'] = np.argmax(sparse_labels, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.223729Z","iopub.execute_input":"2024-03-21T09:29:35.223967Z","iopub.status.idle":"2024-03-21T09:29:35.232788Z","shell.execute_reply.started":"2024-03-21T09:29:35.223947Z","shell.execute_reply":"2024-03-21T09:29:35.231812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns=label_cols + ['label'])\ny = train['label'].values","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.235287Z","iopub.execute_input":"2024-03-21T09:29:35.235705Z","iopub.status.idle":"2024-03-21T09:29:35.242139Z","shell.execute_reply.started":"2024-03-21T09:29:35.235674Z","shell.execute_reply":"2024-03-21T09:29:35.241235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.243216Z","iopub.execute_input":"2024-03-21T09:29:35.243628Z","iopub.status.idle":"2024-03-21T09:29:35.276402Z","shell.execute_reply.started":"2024-03-21T09:29:35.243602Z","shell.execute_reply":"2024-03-21T09:29:35.27562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.277392Z","iopub.execute_input":"2024-03-21T09:29:35.277656Z","iopub.status.idle":"2024-03-21T09:29:35.283048Z","shell.execute_reply.started":"2024-03-21T09:29:35.277635Z","shell.execute_reply":"2024-03-21T09:29:35.282076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking output on train df\ndf_train = named_preprocessing_pipeline.fit_transform(X)\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.284163Z","iopub.execute_input":"2024-03-21T09:29:35.284518Z","iopub.status.idle":"2024-03-21T09:29:35.309192Z","shell.execute_reply.started":"2024-03-21T09:29:35.284487Z","shell.execute_reply":"2024-03-21T09:29:35.308343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import  StandardScaler,RobustScaler\n\n# Using Standard Scaler or Robust Scaler to scale numeric variables\n\nclass StandardScalerNamed(StandardScaler, TransformerMixin):\n    def get_feature_names_out(self, X, y=None):\n        return X.columns.tolist()\n\n    def transform(self, X, y=None):\n        transformed = super().transform(X, y)\n        return pd.DataFrame(transformed, columns=X.columns)\n\n\nclass RobustScalerNamed(RobustScaler, TransformerMixin):\n    def get_feature_names_out(self, X, y=None):\n        return X.columns.tolist()\n\n    def transform(self, X, y=None):\n        transformed = super().transform(X, y)\n        return pd.DataFrame(transformed, columns=X.columns)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.310271Z","iopub.execute_input":"2024-03-21T09:29:35.310669Z","iopub.status.idle":"2024-03-21T09:29:35.318499Z","shell.execute_reply.started":"2024-03-21T09:29:35.310635Z","shell.execute_reply":"2024-03-21T09:29:35.31735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelling_pipeline = Pipeline(named_preprocessing_pipeline.steps + [('scale',RobustScaler().set_output(transform='pandas')),])\nmodelling_pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.319558Z","iopub.execute_input":"2024-03-21T09:29:35.319864Z","iopub.status.idle":"2024-03-21T09:29:35.338628Z","shell.execute_reply.started":"2024-03-21T09:29:35.319836Z","shell.execute_reply":"2024-03-21T09:29:35.337719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.pipeline import make_pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.33956Z","iopub.execute_input":"2024-03-21T09:29:35.339816Z","iopub.status.idle":"2024-03-21T09:29:35.578659Z","shell.execute_reply.started":"2024-03-21T09:29:35.339795Z","shell.execute_reply":"2024-03-21T09:29:35.577877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost baseline model\nxgb_model = XGBClassifier(\n                          objective='multi:softprob',\n                          eval_metric='mlogloss',\n                          )\n\nxgb_pipeline = make_pipeline(modelling_pipeline, xgb_model)\nxgb_pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.584322Z","iopub.execute_input":"2024-03-21T09:29:35.584625Z","iopub.status.idle":"2024-03-21T09:29:35.62282Z","shell.execute_reply.started":"2024-03-21T09:29:35.584601Z","shell.execute_reply":"2024-03-21T09:29:35.621934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_validate, StratifiedKFold\nfrom sklearn.metrics import f1_score, roc_auc_score\n\n# Number of folds\nn_splits = 10\n\n# Adjusting parameters of StratifiedKFold\nstratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# Cross-validation results\ncv_results = []\n\n# Stratified k-fold cross-validation\nfor fold, (train_idx, val_idx) in enumerate(stratkf.split(X, y)):\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n    \n    # Fit the model\n    xgb_pipeline.fit(X_train, y_train)\n\n    # Predictions on the validation set\n    y_val_pred_prob = xgb_pipeline.predict_proba(X_val)\n    y_pred = xgb_pipeline.predict(X_val)\n        \n    # Calculate evaluation metrics\n    f1 = f1_score(y_val, y_pred, average='weighted')\n    roc_auc = roc_auc_score(y_val, y_val_pred_prob, multi_class='ovr')\n\n    print(f'Fold {fold + 1}, AUC Score on Validation Set: {roc_auc}')\n    print(f'Fold {fold + 1}, F1 Score on Validation Set: {f1}')\n    print('-' * 70)\n\n    # Results\n    cv_results.append(roc_auc)\n\n# Average cross-validation result\naverage_cv_result = sum(cv_results) / n_splits\nprint(f'\\nAverage AUC-score across {n_splits} folds: {average_cv_result}')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:29:35.624303Z","iopub.execute_input":"2024-03-21T09:29:35.624596Z","iopub.status.idle":"2024-03-21T09:30:05.461116Z","shell.execute_reply.started":"2024-03-21T09:29:35.62457Z","shell.execute_reply":"2024-03-21T09:30:05.46029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import  confusion_matrix\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nxgb_pipeline.fit(X_train,y_train)\n\npredictions_xgb = xgb_pipeline.predict(X_val)\n\ncm_xgb = confusion_matrix(y_val, predictions_xgb)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults','None'])\n\nplt.figure(figsize=(10, 10))\n\n# Plot the confusion matrix\ndisp.plot(ax=plt.gca())  # Use the current axes\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:30:05.462346Z","iopub.execute_input":"2024-03-21T09:30:05.462952Z","iopub.status.idle":"2024-03-21T09:30:08.509747Z","shell.execute_reply.started":"2024-03-21T09:30:05.462924Z","shell.execute_reply":"2024-03-21T09:30:08.508825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Seems to have difficulty to seperate 'Other_Faults' and 'Bumps' properly","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>6 |</span></b> <b>FEATURE ANALYSIS</b></div>","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:41:00.393252Z","iopub.execute_input":"2024-03-06T14:41:00.393693Z","iopub.status.idle":"2024-03-06T14:41:00.39915Z","shell.execute_reply.started":"2024-03-06T14:41:00.393657Z","shell.execute_reply":"2024-03-06T14:41:00.397961Z"}}},{"cell_type":"markdown","source":"### <b><span style='color:#FFCE30'> 6.1 |</span> Permutation Importance</b>","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(xgb_pipeline, random_state=42).fit(X, y)\neli5.show_weights(perm, feature_names = X.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:30:08.511019Z","iopub.execute_input":"2024-03-21T09:30:08.511313Z","iopub.status.idle":"2024-03-21T09:30:47.950828Z","shell.execute_reply.started":"2024-03-21T09:30:08.511289Z","shell.execute_reply":"2024-03-21T09:30:47.949851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#FFCE30'> 6.2 |</span> SHAP Values</b>","metadata":{}},{"cell_type":"code","source":"import shap\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Assuming xgb_pipeline is a Pipeline with XGBoost as its last step\nxgb_model = xgb_pipeline.steps[-1][1]\n\nmy_model = xgb_model.fit(X_train,y_train)\n\nexplainer = shap.TreeExplainer(my_model)\nshap_values = explainer.shap_values(X_val)\n\nshap.summary_plot(shap_values, X_val)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:30:47.952159Z","iopub.execute_input":"2024-03-21T09:30:47.953039Z","iopub.status.idle":"2024-03-21T09:31:08.222938Z","shell.execute_reply.started":"2024-03-21T09:30:47.953003Z","shell.execute_reply":"2024-03-21T09:31:08.221987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#FFCE30'> 6.3 |</span> Feature Importance</b>","metadata":{}},{"cell_type":"code","source":"TOP = 20\n\nfeature_importance = xgb_model.feature_importances_\n\n# Get the feature names from 'X'\nfeature_names = X.columns\n\n# Sort the feature importances and get the indices of the sorted array\nsorted_idx = np.argsort(feature_importance)\n\n# Plot only the top 'TOP' features\nfig = plt.figure(figsize=(10, 8))\nplt.barh(np.arange(len(sorted_idx))[-TOP:], feature_importance[sorted_idx][-TOP:], align='center')\nplt.yticks(np.arange(len(sorted_idx))[-TOP:], feature_names[sorted_idx][-TOP:])\nplt.title(f'Feature Importance - Top {TOP}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.224126Z","iopub.execute_input":"2024-03-21T09:31:08.224778Z","iopub.status.idle":"2024-03-21T09:31:08.607169Z","shell.execute_reply.started":"2024-03-21T09:31:08.224751Z","shell.execute_reply":"2024-03-21T09:31:08.606093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an empty DataFrame to store SHAP values\nshap_df = pd.DataFrame()\n\n# Iterate over each class\nfor class_index in range(7):  # Assuming you have 7 classes\n    # Create a DataFrame for SHAP values of the current class\n    class_shap_df = pd.DataFrame(data=shap_values[class_index], columns=X.columns)\n    # Append the DataFrame to the shap_df DataFrame\n    shap_df = pd.concat([shap_df, class_shap_df], ignore_index=True)\n\n\n# Feature Importance\nfeature_importance_dict = dict(zip(X.columns, feature_importance))\nsorted_feature_importance = {k: v for k, v in sorted(feature_importance_dict.items(), key=lambda item: item[1], reverse=True)}\n\n# Combine all rankings\nfeatures = list(X.columns)\nperm_ranking = [features[index] for index in perm.feature_importances_.argsort()[::-1]]\nshap_ranking = [features[index] for index in shap_df.abs().mean().argsort()[::-1]]\nfeature_importance_ranking = [feature for feature, _ in sorted_feature_importance.items()]\n\n\n# Create DataFrame\ndata = {\n    \"Permutation Importance Rank\": perm_ranking,\n    \"SHAP Values Rank\": shap_ranking,\n    \"Feature Importance Rank\": feature_importance_ranking\n}\n\ndf = pd.DataFrame(data)\ndf.head(20)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.608369Z","iopub.execute_input":"2024-03-21T09:31:08.60871Z","iopub.status.idle":"2024-03-21T09:31:08.637207Z","shell.execute_reply.started":"2024-03-21T09:31:08.608684Z","shell.execute_reply":"2024-03-21T09:31:08.636272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dictionary to store combined rank scores\ncombined_rank = {}\n\n# Compute combined rank score for each feature\nfor feature in X.columns:\n    perm_rank = perm_ranking.index(feature) + 1\n    shap_rank = shap_ranking.index(feature) + 1\n    importance_rank = feature_importance_ranking.index(feature) + 1\n    \n    # Calculate combined rank score\n    combined_rank[feature] = perm_rank + shap_rank + importance_rank\n\n# Create DataFrame for combined rank scores\ncombined_rank_df = pd.DataFrame(list(combined_rank.items()), columns=['Feature Name', 'Importance Rank Score'])\n\n# Sort DataFrame by combined rank score in ascending order\ncombined_rank_df = combined_rank_df.sort_values(by='Importance Rank Score')\n\n# Select top 15 features\ntop_15_features = combined_rank_df.head(15)\n\ntop_15_features\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.638295Z","iopub.execute_input":"2024-03-21T09:31:08.638645Z","iopub.status.idle":"2024-03-21T09:31:08.652681Z","shell.execute_reply.started":"2024-03-21T09:31:08.638615Z","shell.execute_reply":"2024-03-21T09:31:08.651814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_15_features['Feature Name'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.653954Z","iopub.execute_input":"2024-03-21T09:31:08.654291Z","iopub.status.idle":"2024-03-21T09:31:08.662052Z","shell.execute_reply.started":"2024-03-21T09:31:08.654261Z","shell.execute_reply":"2024-03-21T09:31:08.661134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>7 |</span></b> <b>XGBOOST MODEL</b></div>","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:41:37.815635Z","iopub.execute_input":"2024-03-06T14:41:37.816803Z","iopub.status.idle":"2024-03-06T14:41:37.823398Z","shell.execute_reply.started":"2024-03-06T14:41:37.816748Z","shell.execute_reply":"2024-03-06T14:41:37.822117Z"}}},{"cell_type":"code","source":"# Define the list of selected columns you want to keep\nselected_columns = [\n  'Steel_Plate_Thickness',\n 'Length_of_Conveyer',\n 'Orientation_Index',\n 'Outside_X_Index',\n 'Edges_Y_Index',\n 'Minimum_of_Luminosity',\n 'LogOfAreas',\n 'Pixels_Areas',\n 'X_Perimeter',\n 'Log_Y_Index',\n 'Luminosity_Index',\n 'TypeOfSteel_A300',\n 'Empty_Index',\n 'Edges_Index',\n 'Log_X_Index'\n] \n\n# Select only the desired columns from the DataFrame\nX_xgb = X[selected_columns]\nX_xgb","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.663124Z","iopub.execute_input":"2024-03-21T09:31:08.663393Z","iopub.status.idle":"2024-03-21T09:31:08.688595Z","shell.execute_reply.started":"2024-03-21T09:31:08.663371Z","shell.execute_reply":"2024-03-21T09:31:08.687677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_xgb.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.689596Z","iopub.execute_input":"2024-03-21T09:31:08.689818Z","iopub.status.idle":"2024-03-21T09:31:08.702073Z","shell.execute_reply.started":"2024-03-21T09:31:08.689799Z","shell.execute_reply":"2024-03-21T09:31:08.701083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_xgb.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.703163Z","iopub.execute_input":"2024-03-21T09:31:08.703656Z","iopub.status.idle":"2024-03-21T09:31:08.711257Z","shell.execute_reply.started":"2024-03-21T09:31:08.703624Z","shell.execute_reply":"2024-03-21T09:31:08.710467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>8 |</span></b> <b>HYPERPARAMETER TUNING</b></div>","metadata":{}},{"cell_type":"code","source":"# import optuna\n# from sklearn.model_selection import  cross_val_score\n\n# import warnings\n# # Set global warning filter\n# warnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.712564Z","iopub.execute_input":"2024-03-21T09:31:08.712839Z","iopub.status.idle":"2024-03-21T09:31:08.718018Z","shell.execute_reply.started":"2024-03-21T09:31:08.712817Z","shell.execute_reply":"2024-03-21T09:31:08.717133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def objective_xgb(trial):\n#     \"\"\"Define the objective function for XGBClassifier\"\"\"\n\n#     params = {\n#     'max_depth': trial.suggest_int('max_depth', 5, 10),\n#     'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n#     'n_estimators': trial.suggest_int('n_estimators', 150, 1000),\n#     'subsample': trial.suggest_float('subsample', 0.01, 1.0),\n#     'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n#     'objective': 'multi:softprob',  # Multiclass classification\n#     'num_class': 7,  # Specify the number of classes\n#     'eval_metric': 'mlogloss',  # Use 'mlogloss' for multiclass log loss optimization\n#     'verbosity': 0,  # Set verbosity to 0 for less output\n#     }\n\n#     xgb_model = XGBClassifier(**params)\n\n#     # Assuming 'skf' is your StratifiedKFold object\n#     skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n#     # Change scoring to 'neg_log_loss'\n#     cv = -cross_val_score(xgb_model, X_xgb, y, cv=skf, scoring='neg_log_loss').mean()\n\n#     return cv\n\n# # Create an Optuna study object\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective_xgb, n_trials=50)\n\n# # Get the best parameters\n# best_params_xgb = study.best_params\n# print(\"Best Hyperparameters for XGBoost:\", best_params_xgb)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.718992Z","iopub.execute_input":"2024-03-21T09:31:08.719247Z","iopub.status.idle":"2024-03-21T09:31:08.728713Z","shell.execute_reply.started":"2024-03-21T09:31:08.719218Z","shell.execute_reply":"2024-03-21T09:31:08.727941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Best Hyperparameters for XGBoost: {'max_depth': 10, 'learning_rate': 0.9472450516762687, 'n_estimators': 688, 'subsample': 0.09079473120748476, 'colsample_bytree': 0.37465855668049536}\n- Best is trial 30 with value: 8.044855124346752.","metadata":{}},{"cell_type":"code","source":"# # Define the list of selected columns you want to keep\n# selected_columns = [\n#   'Steel_Plate_Thickness',\n#  'Length_of_Conveyer',\n#  'Orientation_Index',\n#  'Outside_X_Index',\n#  'Edges_Y_Index',\n#  'Minimum_of_Luminosity',\n#  'LogOfAreas',\n#  'Pixels_Areas',\n#  'X_Perimeter',\n#  'Log_Y_Index',\n#  'Luminosity_Index',\n#  'TypeOfSteel_A300',\n#  'Empty_Index',\n#  'Edges_Index',\n#  'Log_X_Index', 'id'\n# ] \n\n# # Select only the desired columns from the DataFrame\n# X_xgb = X[selected_columns]\n# X_xgb","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.72969Z","iopub.execute_input":"2024-03-21T09:31:08.729948Z","iopub.status.idle":"2024-03-21T09:31:08.738586Z","shell.execute_reply.started":"2024-03-21T09:31:08.729927Z","shell.execute_reply":"2024-03-21T09:31:08.737817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #XGBoost best parameters {'max_depth': 10, 'learning_rate': 0.9472450516762687, 'n_estimators': 688, 'subsample': 0.09079473120748476, 'colsample_bytree': 0.37465855668049536}\n# xgb_params_optuna = {'max_depth': 10, 'learning_rate': 0.9472450516762687, 'n_estimators': 688, 'subsample': 0.09079473120748476, 'colsample_bytree': 0.37465855668049536,                    \n#                     'objective': 'multi:softprob',\n#                     'eval_metric': 'mlogloss'\n                    \n#                     }\n\n\n# # XGBoost baseline model\n# xgb_model = XGBClassifier(**xgb_params_optuna)\n\n# xgb_pipeline = make_pipeline(modelling_pipeline, xgb_model)\n# xgb_pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.739403Z","iopub.execute_input":"2024-03-21T09:31:08.739665Z","iopub.status.idle":"2024-03-21T09:31:08.752359Z","shell.execute_reply.started":"2024-03-21T09:31:08.739644Z","shell.execute_reply":"2024-03-21T09:31:08.751503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import cross_validate, StratifiedKFold\n# from sklearn.metrics import f1_score, roc_auc_score\n\n# # Number of folds\n# n_splits = 10\n\n# # Adjusting parameters of StratifiedKFold\n# stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# # Cross-validation results\n# cv_results = []\n\n# # Stratified k-fold cross-validation\n# for fold, (train_idx, val_idx) in enumerate(stratkf.split(X_xgb, y)):\n#     X_train, X_val = X_xgb.iloc[train_idx], X_xgb.iloc[val_idx]\n#     y_train, y_val = y[train_idx], y[val_idx]\n    \n#     # Fit the model\n#     xgb_pipeline.fit(X_train, y_train)\n\n#     # Predictions on the validation set\n#     y_val_pred_prob = xgb_pipeline.predict_proba(X_val)\n#     y_pred = xgb_pipeline.predict(X_val)\n        \n#     # Calculate evaluation metrics\n#     f1 = f1_score(y_val, y_pred, average='weighted')\n#     roc_auc = roc_auc_score(y_val, y_val_pred_prob, multi_class='ovr')\n\n#     print(f'Fold {fold + 1}, AUC Score on Validation Set: {roc_auc}')\n#     print(f'Fold {fold + 1}, F1 Score on Validation Set: {f1}')\n#     print('-' * 70)\n\n#     # Results\n#     cv_results.append(roc_auc)\n\n# # Average cross-validation result\n# average_cv_result = sum(cv_results) / n_splits\n# print(f'\\nAverage AUC-score across {n_splits} folds: {average_cv_result}')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.753495Z","iopub.execute_input":"2024-03-21T09:31:08.754404Z","iopub.status.idle":"2024-03-21T09:31:08.762489Z","shell.execute_reply.started":"2024-03-21T09:31:08.754379Z","shell.execute_reply":"2024-03-21T09:31:08.761638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import ConfusionMatrixDisplay\n# from sklearn.metrics import  confusion_matrix\n\n# X_train, X_val, y_train, y_val = train_test_split(X_xgb, y, test_size=0.2, random_state=42)\n\n# xgb_pipeline.fit(X_train,y_train)\n\n# predictions_xgb = xgb_pipeline.predict(X_val)\n\n# cm_xgb = confusion_matrix(y_val, predictions_xgb)\n\n# disp = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults','None'])\n\n# plt.figure(figsize=(10, 10))\n\n# # Plot the confusion matrix\n# disp.plot(ax=plt.gca())  # Use the current axes\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.763545Z","iopub.execute_input":"2024-03-21T09:31:08.763797Z","iopub.status.idle":"2024-03-21T09:31:08.776293Z","shell.execute_reply.started":"2024-03-21T09:31:08.763776Z","shell.execute_reply":"2024-03-21T09:31:08.775483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>8 |</span></b> <b>SUBMISSION</b></div>","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:42:06.915463Z","iopub.execute_input":"2024-03-06T14:42:06.915918Z","iopub.status.idle":"2024-03-06T14:42:06.921497Z","shell.execute_reply.started":"2024-03-06T14:42:06.915881Z","shell.execute_reply":"2024-03-06T14:42:06.920491Z"}}},{"cell_type":"code","source":"# # Select only the desired columns from the DataFrame\n# test_xgb = test[selected_columns]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.777224Z","iopub.execute_input":"2024-03-21T09:31:08.777511Z","iopub.status.idle":"2024-03-21T09:31:08.785925Z","shell.execute_reply.started":"2024-03-21T09:31:08.777483Z","shell.execute_reply":"2024-03-21T09:31:08.785086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_1 = {\n    \"random_state\": 18,\n    \"n_estimators\": 1800,\n    \"learning_rate\": 0.006,\n    \"gamma\": 0.44,\n    \"subsample\": 0.7,\n    \"colsample_bytree\": 0.38,\n    \"max_depth\": 5,\n    \"min_child_weight\": 4,\n    \"reg_lambda\": 1.8e-06,\n    \"reg_alpha\": 0.54,\n    \"booster\": \"gbtree\",\n    \"verbosity\": 0,\n    \"device_type\": \"cuda\",\n    \"tree_method\": \"gpu_hist\",\n    \"grow_policy\": \"depthwise\",\n}  \n\nparams_2 = {\n    \"n_estimators\": 703,\n    \"learning_rate\": 0.023358116742747285,\n    \"gamma\": 0.24997920132991797,\n    \"subsample\": 0.8841265541346639,\n    \"colsample_bytree\": 0.362499715714305,\n    \"max_depth\": 5,\n    \"min_child_weight\": 5,\n    \"reg_lambda\": 2.9660886967874625,\n    \"reg_alpha\": 0.00011509254946941848,\n    \"booster\": \"gbtree\",\n    \"verbosity\": 0,\n    \"grow_policy\": \"depthwise\",\n    \"device_type\": \"cuda\",\n    \"tree_method\": \"gpu_hist\",\n}  \n\nparams_3 = {\n    \"verbosity\": 0,\n    \"learning_rate\": 0.02767540293640535,\n    \"n_estimators\": 494,\n    \"reg_alpha\": 1.5855453969671037e-06,\n    \"reg_lambda\": 1.4155529076600075,\n    \"max_depth\": 5,\n    \"colsample_bytree\": 0.46589178614541227,\n    \"subsample\": 0.8504122771965839,\n    \"min_child_weight\": 3,\n    \"device\": \"cuda\",\n    \"tree_method\": \"hist\",\n    \"random_state\": 18,\n} \n\nparams_4 = {\n    \"n_estimators\": 1235,\n    \"learning_rate\": 0.008352405007099802,\n    \"gamma\": 0.6499918347241912,\n    \"subsample\": 0.9116532305497375,\n    \"colsample_bytree\": 0.49334879814671045,\n    \"max_depth\": 7,\n    \"min_child_weight\": 1,\n    \"reg_lambda\": 1.7005084366184795,\n    \"reg_alpha\": 0.0059679946773570774,\n    \"device\": \"cuda\",\n    \"tree_method\": \"hist\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.786806Z","iopub.execute_input":"2024-03-21T09:31:08.787062Z","iopub.status.idle":"2024-03-21T09:31:08.80075Z","shell.execute_reply.started":"2024-03-21T09:31:08.787041Z","shell.execute_reply":"2024-03-21T09:31:08.799911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost baseline model\nxgb_model_1 = XGBClassifier(**params_1)\nxgb_model_2 = XGBClassifier(**params_2)\nxgb_model_3 = XGBClassifier(**params_3)\nxgb_model_4 = XGBClassifier(**params_4)\n\n\nxgb_pipeline_1 = make_pipeline(modelling_pipeline, xgb_model_1)\nxgb_pipeline_2 = make_pipeline(modelling_pipeline, xgb_model_2)\nxgb_pipeline_3 = make_pipeline(modelling_pipeline, xgb_model_3)\nxgb_pipeline_4 = make_pipeline(modelling_pipeline, xgb_model_4)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.801835Z","iopub.execute_input":"2024-03-21T09:31:08.802106Z","iopub.status.idle":"2024-03-21T09:31:08.810469Z","shell.execute_reply.started":"2024-03-21T09:31:08.802085Z","shell.execute_reply":"2024-03-21T09:31:08.809659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nensemble_model = VotingClassifier(estimators=[\n    ('xgb1', xgb_pipeline_1),\n    ('xgb2', xgb_pipeline_2),\n    ('xgb3', xgb_pipeline_3),\n    ('xgb4', xgb_pipeline_4),\n    \n  \n            \n]\n                                  , voting='soft',\n                                  weights = [0.4,0.4,0.1,0.1]) \n\nensemble_model","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:08.811492Z","iopub.execute_input":"2024-03-21T09:31:08.811797Z","iopub.status.idle":"2024-03-21T09:31:09.087592Z","shell.execute_reply.started":"2024-03-21T09:31:08.811768Z","shell.execute_reply":"2024-03-21T09:31:09.086491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the xgb model model\nensemble_model.fit(X, y)\n\n# Create submission file with probability predictions\npredictions = ensemble_model.predict_proba(test)[:, :-1]\n\nsample_submission[label_cols] = predictions\nsample_submission.to_csv('submission_baseline_xgb.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:31:09.089295Z","iopub.execute_input":"2024-03-21T09:31:09.089651Z","iopub.status.idle":"2024-03-21T09:32:10.057005Z","shell.execute_reply.started":"2024-03-21T09:31:09.089621Z","shell.execute_reply":"2024-03-21T09:32:10.056203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:32:10.058036Z","iopub.execute_input":"2024-03-21T09:32:10.058303Z","iopub.status.idle":"2024-03-21T09:32:10.074782Z","shell.execute_reply.started":"2024-03-21T09:32:10.05828Z","shell.execute_reply":"2024-03-21T09:32:10.073816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Set the style of the visualization\nsns.set(style=\"whitegrid\")\n\n# Specify the columns you want to plot (excluding the 'id' column)\ncolumns_to_plot = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n\n# Plot density plot for each category\nplt.figure(figsize=(12, 8))\nfor column in columns_to_plot:\n    sns.kdeplot(data=sample_submission[column], label=column, fill=True)\n    \nplt.title('Density Plot of Predicted Probabilities for Each Class')\nplt.xlabel('Predicted Probabilities')\nplt.ylabel('Density')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:32:10.075893Z","iopub.execute_input":"2024-03-21T09:32:10.076134Z","iopub.status.idle":"2024-03-21T09:32:11.524219Z","shell.execute_reply.started":"2024-03-21T09:32:10.076114Z","shell.execute_reply":"2024-03-21T09:32:11.523096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}