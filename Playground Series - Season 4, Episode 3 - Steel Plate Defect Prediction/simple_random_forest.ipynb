{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load in data\n",
    "df_train = pd.read_csv('/home/tomruge/Schreibtisch/Data/Kaggle/playground-series-s4e3/train.csv')\n",
    "df_test = pd.read_csv('/home/tomruge/Schreibtisch/Data/Kaggle/playground-series-s4e3/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class model_class:\n",
    "    def __init__(self, df_train, df_test, target = [], drop = []):\n",
    "        self.df_train = df_train.drop(columns = drop)\n",
    "        self.df_test = df_test.drop(columns = drop)\n",
    "        self.target = target\n",
    "        self.drop = drop\n",
    "    \n",
    "    def fit(self,params):\n",
    "        mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=True)\n",
    "        roc_score = []\n",
    "        for train_index, test_index in mskf.split(self.df_train, self.df_train[self.target]):\n",
    "            X_train = self.df_train.loc[train_index].drop(columns = self.target)\n",
    "            X_test = self.df_train.loc[test_index].drop(columns = self.target)\n",
    "            y_train = self.df_train.loc[train_index][self.target]\n",
    "            y_test = self.df_train.loc[test_index][self.target]\n",
    "            self.model = RandomForestClassifier(**params)\n",
    "            self.model.fit(X_train, y_train)\n",
    "            y_pred = self.model.predict_proba(X_test)\n",
    "            # extract the probability of the positive class\n",
    "            y_pred = np.array([array[:,1] for array in y_pred]).T\n",
    "            #print('UNiques: ', np.unique(y_pred))\n",
    "            # shape ypred\n",
    "            #print(roc_auc_score(y_test, y_pred))\n",
    "            roc_score.append(roc_auc_score(y_test, y_pred))\n",
    "        return np.mean(roc_score)\n",
    "    \n",
    "    def predict(self, params):\n",
    "        # fit to all the data\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(self.df_train.drop(columns = self.target), self.df_train[self.target])\n",
    "        prediction =  model.predict_proba(self.df_test)\n",
    "        y_pred = np.array([array[:,1] for array in prediction]).T\n",
    "        return y_pred\n",
    "    \n",
    "    def objective(self,trial):\n",
    "        # params for optimizing the random forrest, use many, but make sure to use compatible ones\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 32),\n",
    "            \"max_features\": trial.suggest_int(\"max_features\", 1, 32),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        }\n",
    "        score = self.fit(params)\n",
    "        return score\n",
    "     \n",
    "    def find_params(self):\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(self.objective, n_trials=100, n_jobs=1)\n",
    "        return study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find good params\n",
    "target_columns = ['Pastry','Z_Scratch','K_Scatch','Stains','Dirtiness','Bumps','Other_Faults']\n",
    "drop_columns = ['id']\n",
    "model = model_class(df_train, df_test, target_columns, drop_columns)\n",
    "params = model.find_params()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "target_columns = ['Pastry','Z_Scratch','K_Scatch','Stains','Dirtiness','Bumps','Other_Faults']\n",
    "drop_columns = ['id']\n",
    "model = model_class(df_train, df_test, target_columns, drop_columns)\n",
    "best_params = {'n_estimators': 94, 'max_depth': 17, 'min_samples_split': 21, 'min_samples_leaf': 28, 'max_features': 9, 'criterion': 'entropy', 'bootstrap': False}\n",
    "# make predictions and save them\n",
    "predicted_values = model.predict(params=best_params)\n",
    "predictions = pd.DataFrame(np.column_stack((df_test['id'].astype('Int32'), predicted_values)), columns = ['id', 'Pastry','Z_Scratch','K_Scatch','Stains','Dirtiness','Bumps','Other_Faults'])\n",
    "\n",
    "# save predictions\n",
    "predictions.to_csv('/home/tomruge/Schreibtisch/Data/Kaggle/playground-series-s4e3/predictions_simplederandom_forest.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
