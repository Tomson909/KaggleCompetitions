{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# load in data\n",
    "df_train = pd.read_csv('/home/tomruge/Schreibtisch/Data/Kaggle/playground-series-s4e3/train.csv')\n",
    "df_test = pd.read_csv('/home/tomruge/Schreibtisch/Data/Kaggle/playground-series-s4e3/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class model_decision_tree:\n",
    "    def __init__(self, train, test, target, drop = []):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.target = target\n",
    "        self.drop = drop\n",
    "    \n",
    "    def fit(self, params = {}):\n",
    "        # running fit multiple times for different validation and train sets to get a better estimate for the prediction\n",
    "        predictions = []\n",
    "        for i in range(5):\n",
    "            print('i: ', i)\n",
    "            # MultilabelStratifiedKFold splits 5 times, but the splits are not overlapping\n",
    "            mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            predictions_1_iteration = np.zeros((len(self.train),len(self.target)))\n",
    "            #print('i: ', i)\n",
    "            for fold, (train_index, val_index) in enumerate(mskf.split(self.train.drop(self.target, axis=1), self.train[self.target])):\n",
    "                X_train, X_val = self.train.drop(self.target, axis=1).iloc[train_index], self.train.drop(self.target, axis=1).iloc[val_index]\n",
    "                y_train, y_val = self.train[self.target].iloc[train_index], self.train[self.target].iloc[val_index]\n",
    "\n",
    "                model = RandomForestClassifier(random_state = i+fold,n_jobs=-1,**params)\n",
    "                model.fit(X_train, y_train)\n",
    "                predictions_1_iteration[val_index] = model.predict(X_val)   \n",
    "            predictions.append(predictions_1_iteration)\n",
    "        # get the mean of the predictions\n",
    "        mean_predictions = np.mean(predictions, axis = 0)\n",
    "        '''print('shape of mean_predictions: ', mean_predictions.shape)\n",
    "        print('mean unique values: ', np.unique(mean_predictions))\n",
    "        print('mean_predictions: ', mean_predictions)'''\n",
    "        # get roc auc score\n",
    "        integral_score = roc_auc_score(self.train[self.target], mean_predictions)\n",
    "        print('roc auc score: ', integral_score)\n",
    "        return integral_score, mean_predictions   \n",
    "     \n",
    "    def prediction(self,params):\n",
    "        predictions = []\n",
    "        for i in range(10):\n",
    "            mskf = MultilabelStratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            for fold, (train_index, val_index) in enumerate(mskf.split(self.train.drop(self.target, axis=1), self.train[self.target])):\n",
    "                X_train, X_val = self.train.drop(self.target, axis=1).iloc[train_index], self.train.drop(self.target, axis=1).iloc[val_index]\n",
    "                y_train, y_val = self.train[self.target].iloc[train_index], self.train[self.target].iloc[val_index]\n",
    "                model = RandomForestClassifier(random_state = i+fold,**params)\n",
    "                model.fit(X_train, y_train)\n",
    "                prediction = model.predict(self.test)\n",
    "                predictions.append(prediction) \n",
    "        # predictions shape\n",
    "        print('predictions shape: ', np.array(predictions).shape)           \n",
    "        mean_predictions = np.mean(predictions, axis = 0)\n",
    "        return mean_predictions\n",
    "    \n",
    "    def objective(self, trial) :\n",
    "        # parameter search space\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 1, 20),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            #'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
    "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "            'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        }\n",
    "        score, _ = self.fit(params)\n",
    "        return score\n",
    "    \n",
    "    def find_params(self):\n",
    "        print('start finding best params')\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(self.objective, n_trials=20, n_jobs = -1)\n",
    "        return study.best_params\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 20:25:25,446] A new study created in memory with name: no-name-5a543416-7d59-465d-b0cd-da534280c497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start finding best params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 20:26:46,993] Trial 0 finished with value: 0.6155516420606773 and parameters: {'n_estimators': 2, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 0 with value: 0.6155516420606773.\n",
      "[I 2024-03-10 20:26:51,921] Trial 3 finished with value: 0.6674313035736413 and parameters: {'n_estimators': 6, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 8, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 3 with value: 0.6674313035736413.\n",
      "[I 2024-03-10 20:26:53,128] Trial 5 finished with value: 0.6125216333457579 and parameters: {'n_estimators': 8, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6674313035736413.\n",
      "[I 2024-03-10 20:26:57,125] Trial 2 finished with value: 0.6148162425616766 and parameters: {'n_estimators': 8, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6674313035736413.\n",
      "[I 2024-03-10 20:27:05,724] Trial 7 finished with value: 0.6122318024811128 and parameters: {'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6674313035736413.\n",
      "[I 2024-03-10 20:27:07,064] Trial 6 finished with value: 0.6321527739175327 and parameters: {'n_estimators': 11, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 3 with value: 0.6674313035736413.\n",
      "[I 2024-03-10 20:27:13,334] Trial 1 finished with value: 0.681165086042901 and parameters: {'n_estimators': 11, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.681165086042901.\n",
      "[I 2024-03-10 20:27:14,499] Trial 4 finished with value: 0.6728616038475594 and parameters: {'n_estimators': 14, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.681165086042901.\n",
      "[I 2024-03-10 20:28:26,670] Trial 8 finished with value: 0.6999444012740329 and parameters: {'n_estimators': 3, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:28:28,076] Trial 11 finished with value: 0.6756903983649308 and parameters: {'n_estimators': 5, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:28:30,070] Trial 10 finished with value: 0.6129800458135993 and parameters: {'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 9, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:28:42,300] Trial 9 finished with value: 0.6599626046160495 and parameters: {'n_estimators': 16, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:28:42,462] Trial 12 finished with value: 0.6112482101145146 and parameters: {'n_estimators': 7, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:28:52,460] Trial 15 finished with value: 0.661900245970029 and parameters: {'n_estimators': 13, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:28:54,580] Trial 14 finished with value: 0.6071059079937244 and parameters: {'n_estimators': 18, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:29:00,484] Trial 13 finished with value: 0.6597569912095248 and parameters: {'n_estimators': 17, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:29:23,018] Trial 16 finished with value: 0.6773553301837609 and parameters: {'n_estimators': 1, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:29:37,892] Trial 17 finished with value: 0.6714767436421377 and parameters: {'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:29:39,519] Trial 18 finished with value: 0.6722338582668363 and parameters: {'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n",
      "[I 2024-03-10 20:29:41,345] Trial 19 finished with value: 0.6722338582668363 and parameters: {'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 8 with value: 0.6999444012740329.\n"
     ]
    }
   ],
   "source": [
    "# find best params\n",
    "target_columns = ['Pastry','Z_Scratch','K_Scatch','Stains','Dirtiness','Bumps','Other_Faults']\n",
    "drop_columns = ['id']\n",
    "model = model_decision_tree(df_train, df_test, target_columns, drop_columns)\n",
    "best_params = model.find_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n",
      "i:  1\n",
      "i:  2\n",
      "i:  3\n",
      "i:  4\n",
      "roc auc score:  0.6624443621663183\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "target_columns = ['Pastry','Z_Scratch','K_Scatch','Stains','Dirtiness','Bumps','Other_Faults']\n",
    "drop_columns = ['id']\n",
    "best_params = {'n_estimators': 3, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'gini'}\n",
    "# predict and save the predictions\n",
    "model = model_decision_tree(df_train, df_test, target_columns, drop_columns)\n",
    "predicted_values = model.fit(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape:  (30, 12814, 7)\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['Pastry','Z_Scratch','K_Scatch','Stains','Dirtiness','Bumps','Other_Faults']\n",
    "drop_columns = ['id']\n",
    "best_params = {'n_estimators': 3, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'gini'}\n",
    "# predict and save the predictions\n",
    "model = model_decision_tree(df_train, df_test, target_columns, drop_columns)\n",
    "predicted_values = model.prediction(best_params)\n",
    "\n",
    "# column 1 must be the id column and the following columns must be the predictions, id column should be integer\n",
    "predictions = pd.DataFrame(np.column_stack((df_test['id'].astype('Int32'), predicted_values)), columns = ['id', 'Pastry','Z_Scratch','K_Scatch','Stains','Dirtiness','Bumps','Other_Faults'])\n",
    "predictions.to_csv('/home/tomruge/Schreibtisch/Data/Kaggle/playground-series-s4e3/predictions_forest.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
